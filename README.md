# üéµ Spotify Genre Classifier: End-to-End NLP Pipeline

![Status](https://img.shields.io/badge/status-in--progress-green)
![Python Version](https://img.shields.io/badge/python-3.11-blue)
![uv](https://img.shields.io/badge/uv-enabled-purple)
![Docker](https://img.shields.io/badge/docker-enabled-blue)
![HuggingFace](https://img.shields.io/badge/Hugging%20Face-RoBERTa-yellow)
![FastAPI](https://img.shields.io/badge/FastAPI-ready-009688)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=Streamlit&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-green)

Este proyecto implementa un sistema End-to-End MLOps para la clasificaci√≥n de g√©neros musicales utilizando Procesamiento de Lenguaje Natural (NPL). El modelo es capaz de predecir m√∫ltiples g√©neros (Multi-Label) para una canci√≥n bas√°ndose √∫nicamente en su letra, utilizando modelos Transformer basado en BERT (RoBERTa).

El repositorio demuestra una arquitectura de software moderna, desacoplando el entrenamiento (realizado en GPU en la nube) de la inferencia (desplegada mediante microservicios Dockerizados), con un enfoque riguroso en la limpieza de datos y la optimizaci√≥n de recursos.

---

## üìã Tabla de Contenidos

- [Arquitectura y Tech Stack](#-arquitectura-y-tech-stack)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Automatizaci√≥n (Makefile)](#%EF%B8%8F-automatizaci√≥n-makefile)
- [Instalaci√≥n y Uso (Docker & Local)](#-instalaci√≥n-y-uso)
- [Dashboard & API](#-dashboard--api)
- [Metodolog√≠a de Data Science](#-metodolog√≠a-de-data-science)
- [Entrenamiento y Resultados](#-entrenamiento-y-resultados)
- [Autor](#-autor)
---

## üõ† Arquitectura y Tech Stack

El proyecto integra herramientas modernas para crear un sistema robusto, modular y escalable:

* **Lenguaje:** Python 3.11
* **Gesti√≥n de Dependencias:** [uv](https://github.com/astral-sh/uv) (Gestor de paquetes de alto rendimiento).
* **Modelado (NPL):** 
    * **Hugging Face Transformers:** Fine-tuning de roberta-base.
    * **PyTorch:** motor de c√°lculo tensorial.
* **Infraestructura del modelo: Hugging Face Hub** (Registro de modelos en la nube). El contenedor descarga el modelo autom√°ticamente al arrancar, manteniendo el repositorio ligero. 
* **Interfaces:** 
    * **FastAPI:** Backend para servir predicciones.
    * **Streamlit:** Frontend interactivo para el usuario final.
* **Entrenamiento:** Google Colab (T4 GPU) con estrategias de ahorro de memoria.
* **Despliegue:** Docker & Docker Compose para orquestaci√≥n de contenedores.

---

## üìÇ Estructura del Proyecto

El c√≥digo sigue una arquitectura de paquete modular, separando configuraci√≥n, l√≥gica y presentaci√≥n:

```text
.
‚îú‚îÄ‚îÄ api/                 # üîå Microservicio Backend (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py          # Endpoints con validaci√≥n Pydantic
‚îú‚îÄ‚îÄ model/               # ü§ñ Cach√© local del modelo (se crea autom√°ticamente)
‚îú‚îÄ‚îÄ notebooks/           # üìì Documentaci√≥n ejecutable (Training Log)
‚îÇ   ‚îî‚îÄ‚îÄ training.ipynb   # Pipeline completo: Carga, Limpieza, Training, Upload
‚îú‚îÄ‚îÄ src/                 # üß† L√≥gica del Negocio compartida
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py     # Clase que gestiona el modelo (descarga y cach√©)
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py # Normalizaci√≥n de texto (Regex)
‚îú‚îÄ‚îÄ ui/                  # üé® Microservicio Frontend (Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ app.py           # Interfaz de usuario
‚îú‚îÄ‚îÄ .env.example         # Plantilla para variables de entorno
‚îú‚îÄ‚îÄ .dockerignore        # Exclusiones para optimizar im√°genes
‚îú‚îÄ‚îÄ .gitignore           # Exclusiones de git
‚îú‚îÄ‚îÄ docker-compose.yml   # Orquestaci√≥n de servicios (API + UI)
‚îú‚îÄ‚îÄ Dockerfile           # Receta de imagen (Multi-stage build con uv)
‚îú‚îÄ‚îÄ Makefile             # üïπÔ∏è Automatizaci√≥n de comandos
‚îú‚îÄ‚îÄ pyproject.toml       # Definici√≥n de dependencias
‚îú‚îÄ‚îÄ uv.lock              # Lockfile para reproducibilidad exacta
‚îî‚îÄ‚îÄ README.md            # Documentaci√≥n
``` 

---

## üïπÔ∏è Automatizaci√≥n (Makefile)

Para facilitar el uso, el proyecto incluye un Makefile que abstrae los comandos complejos.

| Comando | Descripci√≥n |
| :--- | :--- |
| `make help` | Muestra todos los comandos disponibles. |
| `make install` | Instala las dependencias con `uv`. |
| `make api` | Levanta el servidor de la API (FastAPI) en local. |
| `make ui` | Lanza la aplicaci√≥n web (Streamlit). |
| `make docker-build` | Construye la imagen de Docker. |
| `make docker-up` | Levanta todo el sistema (API + Dashboard) en contenedores. |
| `make docker-down` | Apaga todos los contenedores. |
| `make clean` | Limpia archivos de cach√© de Python. |

---

## üíª Instalaci√≥n y Uso

### Configuraci√≥n inicial (opcional)

Si quieres usar tu token de Hugging Face (recomendado para evitar l√≠mites de descarga):

1. Copia el archivo de ejemplo:
   ```bash
   cp .env.example .env
   ```

2. Edita `.env` y a√±ade tu token (cons√≠guelo en https://huggingface.co/settings/tokens):
   ```
   HF_TOKEN=hf_tu_token_real_aqui
   ```

**Nota:** El token no es necesario si el modelo es p√∫blico, pero ayuda a evitar l√≠mites de descarga.

---

### Opci√≥n A: Docker (Recomendada üê≥)

1. Levanta todo el sistema sin preocuparte por dependencias de Python o versiones de CUDA.

    ```bash
    make docker-up
    ```

    (La primera vez tardar√° unos minutos mientras descarga las im√°genes y el modelo RoBERTa de 500MB).

2. **Acceder:**

    * üé® Web App: Abre http://localhost:8501 en tu navegador.

    * ‚öôÔ∏è API Docs: Abre http://localhost:8000/docs.

3. Detener:

    ```bash
    make docker-down
    ```

### Opci√≥n B: Ejecuci√≥n Local (con uv)

Si deseas editar el c√≥digo o desarrollar localmente:

1. **Instalar dependencias:**

    ```bash
    make install
    ```

2. **Ejecutar servicios (en terminales separadas):**

    ```bash
    make api  # Terminal 1: Inicia la API
    make ui   # Terminal 2: Inicia la interfaz
    ```

3. **Acceder:**

    * üé® Web App: http://localhost:8501
    * ‚öôÔ∏è API Docs: http://localhost:8000/docs

**Nota:** El modelo se descarga autom√°ticamente la primera vez y se guarda en la carpeta `model/` para futuras ejecuciones.

---

## üß† Dashboard & API

El sistema expone dos interfaces principales para interactuar con el modelo:

1. **Dashboard Interactivo (Streamlit)**

    Dise√±ado para usuarios finales. Permite:

    * Entrada de Texto: Un √°rea de texto simple para pegar la letra de la canci√≥n a analizar.

    * Visualizaci√≥n de Confianza: Muestra los g√©neros detectados con barras de progreso que indican la probabilidad (confianza) del modelo para cada etiqueta.

    * Feedback en Tiempo Real: Indicadores de carga mientras el modelo realiza la inferencia.

2. **API REST (FastAPI)**

    El motor del sistema, dise√±ado para integraciones.

    * Endpoint `/predict`: Acepta un JSON con la letra y devuelve los g√©neros detectados.

    * Validaci√≥n autom√°tica con Pydantic: Garantiza que los datos de entrada sean correctos.

    * Documentaci√≥n interactiva: Swagger UI disponible en `/docs` para probar la API desde el navegador.

---

## ‚öôÔ∏è Metodolog√≠a de Data Science

El mayor reto de este proyecto no fue el modelo, sino los datos. Se aplic√≥ una estrategia de Data-Centric AI para pasar de un rendimiento pobre a un modelo robusto.

1. **Ingenier√≠a de Datos y Limpieza:**

    * Filtrado de Idioma: Se detect√≥ que el dataset conten√≠a m√∫ltiples idiomas. Se utiliz√≥ langdetect para filtrar y conservar solo el corpus en ingl√©s (97% del total), optimizando el uso de roberta-base (monoling√ºe).

    * Agrupaci√≥n de G√©neros (Label Engineering): El dataset original conten√≠a 88 micro-g√©neros desbalanceados (ej: cloud rap, trap, gangster rap). Se desarroll√≥ un algoritmo de mapeo para consolidarlos en 14 Macro-G√©neros s√≥lidos (Hip-Hop, Rock, Pop, Metal, etc.), mejorando dr√°sticamente la se√±al de aprendizaje.

    * Limpieza de Texto: Eliminaci√≥n de metadatos de Genius (ej: [Chorus], [Verse 1]) mediante Regex.

2. **Modelado:**

    * Arquitectura: RoBERTa (Robustly optimized BERT approach). Se eligi√≥ sobre DistilBERT por su capacidad superior para entender contextos complejos, iron√≠a y slang en ingl√©s.

    * Estrategia Multi-Label: Se utiliz√≥ BCEWithLogitsLoss para permitir que una canci√≥n pertenezca a m√∫ltiples g√©neros simult√°neamente (ej: Rock y Pop).

---

## üìä Entrenamiento y Resultados

El modelo fue entrenado utilizando Google Colab (T4 GPU) con t√©cnicas de optimizaci√≥n de memoria:

* Dataset: ~50.000 canciones.

* Optimizaciones: Mixed Precision (FP16) y Gradient Accumulation (Batch Size efectivo = 16).

* M√©tricas:

    * El modelo final utiliza un umbral de decisi√≥n optimizado de 0.2. Esto corrige el sesgo conservador de la red neuronal, maximizando el F1-Score y la Accuracy en un problema de clasificaci√≥n multietiqueta.

    * El modelo final alcanza un ROC-AUC > 0.90, demostrando una excelente capacidad de separaci√≥n entre clases.

El modelo entrenado se encuentra alojado p√∫blicamente en Hugging Face Hub: Juanpeg1729/genre-classifier.

---

## ‚úíÔ∏è Autor

**Juan Pedro Garc√≠a Sanz**

* **GitHub:** [@Juanpeg1729](https://github.com/Juanpeg1729)
* **LinkedIn:** [Perfil de LinkedIn](https://www.linkedin.com/in/juanpedrogarciasanz)
* **Hugging Face:** [@Juanpeg1279](https://huggingface.co/Juanpeg1729)