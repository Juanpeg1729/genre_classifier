# ğŸµ Spotify Genre Classifier: End-to-End NLP Pipeline

Este proyecto desarrolla un flujo de trabajo completo (End-to-End MLOps) para la clasificaciÃ³n de gÃ©neros musicales utilizando Procesamiento de Lenguaje Natural (NLP). El sistema predice mÃºltiples gÃ©neros para una canciÃ³n basÃ¡ndose Ãºnicamente en su letra, utilizando modelos Transformer.

El enfoque principal de este repositorio es presentar una arquitectura de Deep Learning moderna y eficiente, desacoplando el entrenamiento pesado (en GPU) de la inferencia ligera (en CPU). El proyecto abarca desde la limpieza de texto y tokenizaciÃ³n hasta el fine-tuning de DistilBERT con optimizaciones de memoria (FP16, Gradient Accumulation) y su despliegue como microservicio.

---

## ğŸ“‹ Tabla de Contenidos
- [Arquitectura y Tech Stack](#-arquitectura-y-tech-stack)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Dashboard & API](#-dashboard--api)
- [MetodologÃ­a de ML](#-metodologÃ­a-de-ml)
- [Entrenamiento y resultados](#-entrenamiento-resultado)
- [Autor](#-autor)

---

## ğŸ›  Arquitectura y Tech Stack

El proyecto integra herramientas modernas para crear un sistema robusto, modular y escalable:

* **Lenguaje:** Python 3.11
* **GestiÃ³n de Dependencias:** [uv](https://github.com/astral-sh/uv) (Gestor de paquetes de alto rendimiento).
* **Modelado (NPL):** 
    * **Hugging Face Transformers:** TokenizaciÃ³n y arquitectura del modelo.
    * **PyTorch:** motor de cÃ¡lculo tensorial.
    * **DistilBert:** modelo base (multilingual Cased) optimizado para eficiencia.
* **Infraestructura del modelo: Hugging Face Hub** (Alojamiento del modelo entrenado para mantener el repositorio ligero). 
* **Interfaces:** 
    * **FastAPI:** Backend para servir predicciones.
    * **Streamlit:** Frontend interactivo para el usuario final.
* **Entrenamiento:** Google Colab (T4 GPU) con estrategias de ahorro de memoria.

---

## ğŸ“‚ Estructura del Proyecto

El cÃ³digo sigue una arquitectura de paquete modular, separando configuraciÃ³n, lÃ³gica y presentaciÃ³n:

```text
.
â”œâ”€â”€ api/                 # ğŸ”Œ Backend (FastAPI)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py          # Endpoints de la API
â”œâ”€â”€ notebooks/           # ğŸ““ Notebooks de Jupyter/Colab
â”‚   â””â”€â”€ training.ipynb   # Pipeline de entrenamiento completo
â”œâ”€â”€ src/                 # ğŸ§  LÃ³gica del Negocio
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ predictor.py     # Clase para descarga e inferencia del modelo
â”‚   â””â”€â”€ preprocessing.py # Limpieza y normalizaciÃ³n de texto
â”œâ”€â”€ ui/                  # ğŸ¨ Frontend (Streamlit)
â”‚   â””â”€â”€ app.py           # Interfaz de usuario
â”œâ”€â”€ .gitignore           # Archivos ignorados
â”œâ”€â”€ pyproject.toml       # DefiniciÃ³n de dependencias (uv)
â”œâ”€â”€ uv.lock              # Versiones exactas (Lockfile)
â””â”€â”€ README.md            # DocumentaciÃ³n
``` 

---

## ğŸ’» InstalaciÃ³n y Uso

Este proyecto utiliza **uv** para garantizar la instalaciÃ³n reproducible y rÃ¡pida. 

1. **Clonar y preparar:**

    ```bash 
    git clone https://github.com/Juanpeg1729/genre-classifier.git
    cd genre-classifier
    ```
2. **Instalar dependencias:**
    uv crearÃ¡ automÃ¡ticamente el entorno virtual y sincronizarÃ¡ las dependencias.

    ```bash
    uv sync
    ```

3. **Ejecutar la aplicaciÃ³n:**
    Para probar el sistema completo necesitarÃ¡s dos terminales (una para el backend y otra para el frontend).

    **Terminal 1: Leventar la API.** El modelo se descargarÃ¡ automÃ¡ticamente de Hugging Face la primera vez.

    ```bash
    uv run uvicorn api.main:app --reload
    ```

    La API estarÃ¡ disponible en: http://127.0.0.1:8000/docs

    **Terminal 2: Lanzar el Dashboard.** 

    ```bash
    uv run streamlit run ui/app.py
    ```

    El navegador se abrirÃ¡ automÃ¡ticamente en: http://localhost:8501

---

# ğŸ§  Dashboard & API

El sistema cuenta con dos puntos de entrada:

1. **API REST (FastAPI):** Recibe un JSON con la letra de la canciÃ³n y devuelve una lista de gÃ©neros con sus puntuaciones de confianza. DiseÃ±ada para integraciÃ³n M2M (Machine-to-Machine).

2. **Web App (Streamlit):** Una interfaz amigable donde el usuario puede pegar la letra de una canciÃ³n. Incluye:

    * ValidaciÃ³n de entrada.

    * VisualizaciÃ³n de resultados con barras de confianza.

    * Feedback visual de carga e inferencia.

---

# âš™ï¸ MetodologÃ­a de ML

El nÃºcleo del proyecto es un problema de **ClasificaciÃ³n Multi-Etiqueta** (una canciÃ³n puede ser Pop y Rock simultÃ¡neamente).

1. IngenierÃ­a de Datos:

    * Limpieza de ruido en letras (eliminaciÃ³n de metadatos como [Chorus], [Verse]).

    * CodificaciÃ³n de etiquetas mediante MultiLabelBinarizer (One-Hot Encoding para 80+ gÃ©neros).

1. Arquitectura del Modelo:

    * Se utilizÃ³ DistilBERT-base-multilingual-cased.

    * Por quÃ©: Ofrece un balance Ã³ptimo entre rendimiento (97% de BERT) y velocidad/peso (40% mÃ¡s ligero), crucial para una inferencia en tiempo real.

3. Entrenamiento Optimizado (GPU):

    * Mixed Precision (FP16): ReducciÃ³n del uso de VRAM a la mitad.

    * Gradient Accumulation: SimulaciÃ³n de batches grandes (Size 16) en hardware limitado.

    * Estrategia de Guardado: Checkpoints automÃ¡ticos en la nube y recuperaciÃ³n ante fallos.

4. Ajuste de Umbral:

    * Dado que es un problema multi-label, se optimizÃ³ el umbral de decisiÃ³n (Threshold = 0.2) para maximizar el F1-Score, evitando falsos negativos comunes en modelos conservadores.

---

# ğŸ“Š Entrenamiento y Resultados

El modelo fue entrenado con un dataset de 5.000 canciones.

* PÃ©rdida (Loss): Se utilizÃ³ BCEWithLogitsLoss (Binary Cross Entropy) adaptada para clasificaciÃ³n multi-etiqueta.

* MÃ©tricas: Se priorizÃ³ el F1-Macro y el ROC-AUC para evaluar el rendimiento en clases desbalanceadas.

* Resultados: El modelo demuestra una capacidad sÃ³lida para distinguir gÃ©neros principales y subgÃ©neros correlacionados.

El modelo final estÃ¡ alojado pÃºblicamente en Hugging Face Hub para facilitar su despliegue sin sobrecargar el repositorio.

---

## âœ’ï¸ Autor

**Juan Pedro GarcÃ­a Sanz**

* **GitHub:** [@Juanpeg1729](https://github.com/Juanpeg1729)
* **LinkedIn:** [Perfil de LinkedIn](https://www.linkedin.com/in/juan-pedro-garcÃ­a-sanz-443b31343)
* **Hugging Face:** [@Juanpeg1279](https://huggingface.co/Juanpeg1729)